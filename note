1. 
	If make the condition = (#click>10) , then
		(#session) / (#buy) ~= 4
	but overall is
		(#session) / (#buy) ~= 50
	SO it's a strong condition.

2. 
	Using feature "month/hour bit" with liblinear on {#click>10}
	use 300000 to train, 50000 to valid:
		correctness: 58%
		           predict 0    predict 1
		answer 0      24607       13716
		answer 1       7031        4646
	Which is doing nothingQQ 

3. 
	Using feature "month/cate bit" with liblinear on {#click>10}
	use 300000 to train, 50000 to valid:
		correctness: 62%
		             predict 0   predict 1
	         answer 0      26666      11657
	         answer 1      7376        4301
	Why??? cate should no effect to result?

4.
    Weighting in liblinear is useless orz.
    Weighting only scale #(predict 1), but while scaling,
    .#(predict 1 but is zero) increase with same ratio.

5.
    Using feature "cate bit" with liblinear on {#click>10}:
        Accuracy = 67.234% (33617/50000)
                  predict 0   predict 1
        answer 0      30308        8015
        answer 1       8368        3309
    Best result till now.
    Still get negetive score through.

6. 
	Using feature "is special offer or not" with liblinear on {#click>10}
        Accuracy = 69.076% (34538/50000)
              predict 0   predict 1
        answer 0      31836        6487
        answer 1       8975        2702
        (a1 p1) / (a0 p1) = 0.416525   (>1 then get positive score)
    Best result ever.
    So features are too much? In 3. 5. 6., we can see this tendency.

7.
	Using feature "is special offer or not" with liblinear on {#click>5}
        Accuracy = 74.1615% (148323/200000)
                  predict 0   predict 1
        answer 0     141602       27385
        answer 1      24292        6721
        (a1 p1) / (a0 p1) = 0.245426   (>1 then get positive score)
    Result turned bad if we extend the train/test data.
    Because (buy/all) become smaller (1/4->1/6).
    The real accuracy is stay unchanged.
    (That is, the ratio of (a1 p1)/(a0 p1) * (buy/all) is unchanged)
    So, NOT features too much, but other reason.
    
8. (important) - better refine?
    by data_analysis, know if we delete item with (#click<512),
    we only delete 1/10 data from the dataset.
    Which we can reduce #data 52739->7879.
    then purity(?) of the data is 9/10*6.6 ~= 6
    we will got 6 times compact data with enough features to train.

9.  a1/all = 0.226475 , (a1 p1) / (a0 p1) = 0.961202
    Using feature "cate bits" with liblinear on refine(8, 512)
        Accuracy = 77.2362% (61789/80000)    
                  predict 0   predict 1
        answer 0      59485        2397
        answer 1      15814        2304
        (a1 p1) / (a0 p1) = 0.961202   (>1 then get positive score)
        #answer 1 = 18118
        a1/all = 0.226475
    After deleting redundence items, we reached score 0! orz
    A big improve.
    * I can't achieve this twice. I picked wrong file to train/test?

10. a1/all = 0.222587 , (a1 p1) / (a0 p1) = 0.380659
    Using feature "spec offer" with liblinear on refine(8, 512)
        Accuracy = 72.4575% (57966/80000)
                  predict 0   predict 1
        answer 0      55368        6825
        answer 1      15209        2598
        (a1 p1) / (a0 p1) = 0.380659   (>1 then get positive score)
        #answer 1 = 17807
        a1/all = 0.222587
    only "spec offer" is bad this time.

11. a1/all = 0.249695 , (a1 p1) / (a0 p1) = 0.760697 , refine(8, 4096)
    Using feature "cate bits" with liblinear on refine(8, 4096)
        Accuracy = 73.8805% (40604/54959)
        ./tools/result_01_grid $liblinearprefix-valid.dat res.txt
                  predict 0   predict 1
        answer 0      38595        2641
        answer 1      11714        2009
        (a1 p1) / (a0 p1) = 0.760697   (>1 then get positive score)
        #answer 1 = 13723
        a1/all = 0.249695

12. a1/all = 0.307224 , (a1 p1) / (a0 p1) = 0.648188 , refine(32, 512)
        Accuracy = 62.5812% (1542/2464)
        ./tools/result_01_grid $liblinearprefix-valid.dat res.txt
                  predict 0   predict 1
        answer 0       1238         469
        answer 1        453         304
        (a1 p1) / (a0 p1) = 0.648188   (>1 then get positive score)
        #answer 1 = 757
        a1/all = 0.307224


13. a1/all = 0.136358 ,   (a1 p1) / (a0 p1) = 0.667087 , refine(4, 512)
    a1/all = 0.249695 ,   (a1 p1) / (a0 p1) = 0.692918 , refine(8, 4096)
    Using feature "cate bits, num be click" with liblinear on refine(4, 512)
        Accuracy = 85.9716% (289057/336224)
	          predict 0   predict 1
        answer 0     286412        3965
        answer 1      43202        2645
        (a1 p1) / (a0 p1) = 0.667087   (>1 then get positive score)
        #answer 1 = 45847
        1/all = 0.136358

        Accuracy = 73.1291% (40191/54959)
                predict 0   predict 1
        answer 0      37833        3403
        answer 1      11365        2358
        (a1 p1) / (a0 p1) = 0.692918   (>1 then get positive score)
        #answer 1 = 13723
        a1/all = 0.249695



